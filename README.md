# Random MDP experiments on usage-based step-size adaptation applied to TD


This project contains random MDP experiments evaluating the usage-based step-size adaptation idea (Mahmood & Sutton 2015) applied to true online TD (TOTD) (van Seijen & Sutton 2014) and TD with accumulating traces (TD) (Sutton & Barto 1998).

This project can be imported as an Eclipse Pydev project.

Read or execute `run-rndmdp-experiments.sh` for an example of running the experiments and plotting the python figures.

## References

van Seijen, H., Sutton, R.S. (2014). True online TD(lambda). In *Proceedings of the 31st International Conference on Machine Learning*. JMLR W&CP 32(1):692-700.

Mahmood, A.R., Sutton R.S. (2015). Off-policy learning based on weighted importance sampling with linear computational complexity. In *Proceedings of the 301st Conference on Uncertainty in Arti- ficial Intelligence* (forthcoming).

Sutton, R. S., Barto, A. G. (1998). *Reinforcement Learning: An Introduction*. MIT Press.
